{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3e807d",
   "metadata": {},
   "source": [
    "# Multimodal Breast Cancer Detection Explainability using the Intel® Explainable AI API\n",
    "\n",
    "This application is a multimodal solution for predicting cancer diagnosis using categorized contrast enhanced mammography data and radiology notes. It trains two models - one for image classification and the other for text classification - which can be combined into an ensemble classifier.\n",
    "\n",
    "## Import Dependencies and Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a9723-5dbe-44eb-9baa-eca188e435f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import EvalPrediction, TrainingArguments, pipeline\n",
    "\n",
    "# tlt imports\n",
    "from tlt.datasets import dataset_factory\n",
    "from tlt.models import model_factory\n",
    "\n",
    "# explainability imports\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import string\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\", module = \"matplotlib\\..*\" )\n",
    "\n",
    "# Specify the root directory where the images and annotations are located\n",
    "dataset_dir = os.path.join(os.environ[\"DATASET_DIR\"]) if \"DATASET_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"dataset\")\n",
    "\n",
    "# Specify a directory for output\n",
    "output_dir = os.environ[\"OUTPUT_DIR\"] if \"OUTPUT_DIR\" in os.environ else \\\n",
    "    os.path.join(os.environ[\"HOME\"], \"output\")\n",
    "\n",
    "print(\"Dataset directory:\", dataset_dir)\n",
    "print(\"Output directory:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53162b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Download the images and radiology annotations from https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=109379611 and save in the path `<dataset_dir>/brca/data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93d752-d650-4201-8ccd-0440218b09f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python prepare_nlp_data.py --data_root {dataset_dir}/brca/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27529580-9606-427b-ba37-2493a2a935e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python prepare_vision_data.py --data_root {dataset_dir}/brca/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1a16c-3528-49e1-af6c-6c32bb122964",
   "metadata": {},
   "source": [
    "Image files should have the .jpg extension and be arranged in subfolders for each class. The annotation file should be a .csv. The final brca dataset directory should look something like this:\n",
    "\n",
    "```\n",
    "brca\n",
    "  ├── data\n",
    "  │   ├── PKG - CDD-CESM\n",
    "  │   ├── Medical reports for cases .zip\n",
    "  │   ├── Radiology manual annotations.xlsx\n",
    "  │   └── Radiology_hand_drawn_segmentations_v2.csv\n",
    "  ├── annotation\n",
    "  │   └── annotation.csv\n",
    "  └── vision_images\n",
    "      ├── Benign\n",
    "      │   ├── P100_L_CM_CC.jpg\n",
    "      │   ├── P100_L_CM_MLO.jpg\n",
    "      │   └── ...\n",
    "      ├── Malignant\n",
    "      │   ├── P102_R_CM_CC.jpg\n",
    "      │   ├── P102_R_CM_MLO.jpg\n",
    "      │   └── ...\n",
    "      └── Normal\n",
    "          ├── P100_R_CM_CC.jpg\n",
    "          ├── P100_R_CM_MLO.jpg\n",
    "          └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c3ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input needed - supply the path to the images in the dataset_dir according to your system\n",
    "source_image_path = os.path.join(dataset_dir, 'brca', 'data', 'vision_images')\n",
    "image_path = source_image_path\n",
    "\n",
    "# User input needed - supply the path and name of the annotation file in the dataset_dir\n",
    "source_annotation_path = os.path.join(dataset_dir, 'brca', 'data', 'annotation', 'annotation.csv')\n",
    "annotation_path = source_annotation_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245df47c",
   "metadata": {},
   "source": [
    "### Optional: Group Data by Patient ID\n",
    "\n",
    "This section is not required to run the workload, but it is helpful to assign all of a subject's records to be entirely in the train set or test set. This section will do a random stratification based on patient ID and save new copies of the grouped data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import split_images, split_annotation\n",
    "\n",
    "grouped_image_path = '{}_grouped'.format(source_image_path)\n",
    "\n",
    "if os.path.isdir(grouped_image_path):\n",
    "    print(\"Grouped directory already exists and will be used: {}\".format(grouped_image_path))\n",
    "else:\n",
    "    split_images(source_image_path, grouped_image_path)\n",
    "\n",
    "train_image_path = os.path.join(grouped_image_path, 'train')\n",
    "test_image_path = os.path.join(grouped_image_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import split_images, split_annotation\n",
    "\n",
    "file_dir, file_name = os.path.split(source_annotation_path)\n",
    "grouped_annotation_path = os.path.join(file_dir, '{}_grouped.csv'.format(os.path.splitext(file_name)[0]))\n",
    "\n",
    "if os.path.isfile(grouped_annotation_path):\n",
    "    print(\"Grouped annotation already exists and will be used: {}\".format(grouped_annotation_path))\n",
    "else:\n",
    "    train_dataset, test_dataset = split_annotation(file_dir, file_name, train_image_path, test_image_path)\n",
    "    train_dataset.to_csv(grouped_annotation_path, index=False)\n",
    "    test_dataset.to_csv(grouped_annotation_path[:-4] + '_test.csv', index=False)\n",
    "    print('Grouped training annotation saved to: {}'.format(grouped_annotation_path))\n",
    "    print('Grouped testing annotation saved to: {}'.format(grouped_annotation_path[:-4] + '_test.csv'))\n",
    "\n",
    "train_annotation_path = grouped_annotation_path\n",
    "test_annotation_path = grouped_annotation_path[:-4] + '_test.csv'\n",
    "label_col = 0  # Index of the label column in the grouped data file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9e5cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 1: Image Classification with PyTorch\n",
    "\n",
    "### Get the Model and Dataset\n",
    "Call the model factory to get a pretrained model from PyTorch Hub and the dataset factory to load the images from their location. The `get_model` function returns a model object that will later be used for training. We will use resnet50 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c93b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model = model_factory.get_model(model_name=\"resnet50\", framework='pytorch')\n",
    "\n",
    "# Load the dataset from the custom dataset path\n",
    "train_viz_dataset = dataset_factory.load_dataset(dataset_dir=train_image_path,\n",
    "                                       use_case='image_classification',\n",
    "                                       framework='pytorch')\n",
    "\n",
    "test_viz_dataset = dataset_factory.load_dataset(dataset_dir=test_image_path,\n",
    "                                       use_case='image_classification',\n",
    "                                       framework='pytorch')\n",
    "\n",
    "print(\"Class names:\", str(train_viz_dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472bedd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preparation\n",
    "Once you have your dataset loaded, use the following cell to preprocess the dataset. We split the images into training and validation subsets, resize them to match the model, and then batch the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dcf057",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# shuffle split the training dataset\n",
    "train_viz_dataset.shuffle_split(train_pct=.80, val_pct=.20, seed=3)\n",
    "train_viz_dataset.preprocess(viz_model.image_size, batch_size=batch_size)\n",
    "test_viz_dataset.preprocess(viz_model.image_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cf08c-aecd-4746-9041-ec90cdb2795f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Image dataset analysis\n",
    "\n",
    "Let's take a look at the dataset and verify that we are loading the data correctly. This includes looking at the distributions amongst the training and validation and visual confirmation of the images themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af33b10-8f92-4212-bc83-be83d987d7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a label map function and reverse label map for the dataset\n",
    "def label_map_func(label):\n",
    "        if label == 'Benign':\n",
    "            return 0\n",
    "        elif label == 'Malignant':\n",
    "            return 1\n",
    "        elif label == 'Normal':\n",
    "            return 2\n",
    "    \n",
    "reverse_label_map = {0: 'Benign', 1: 'Malignant', 2: 'Normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b131c6-969c-4c7b-9e20-de0ab6de67af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_label_count = {'Benign': 0, 'Malignant': 0, 'Normal': 0}\n",
    "\n",
    "for x, y in train_viz_dataset.train_subset:\n",
    "    train_label_count[reverse_label_map[y]] += 1\n",
    "\n",
    "print('Training label distribution:')\n",
    "train_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007cf93-868c-445f-b28f-f3383ecd90ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_label_count = {'Benign': 0, 'Malignant': 0, 'Normal': 0}\n",
    "\n",
    "for x, y in train_viz_dataset.validation_subset:\n",
    "    valid_label_count[reverse_label_map[y]] += 1\n",
    "\n",
    "print('Validation label distribution:')\n",
    "valid_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d600e39-c5bc-4224-9798-7d3dea87844a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_label_count = {'Benign': 0, 'Malignant': 0, 'Normal': 0}\n",
    "\n",
    "for x, y in test_viz_dataset.dataset:\n",
    "    test_label_count[reverse_label_map[y]] += 1\n",
    "\n",
    "print('Validation label distribution:')\n",
    "test_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bad41-d9aa-4c73-8d52-1a5905124bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get datsaet distrubtions\n",
    "form = {'type':'domain'}\n",
    "fig = make_subplots(rows=1, cols=3, specs=[[form, form, form]], subplot_titles=['Training', 'Validation', 'Testing'])\n",
    "fig.add_trace(go.Pie(values=list(train_label_count.values()), labels=list(train_label_count.keys())), 1, 1)\n",
    "fig.add_trace(go.Pie(values=list(valid_label_count.values()), labels=list(valid_label_count.keys())), 1, 2)\n",
    "fig.add_trace(go.Pie(values=list(test_label_count.values()), labels=list(valid_label_count.keys())), 1, 3)\n",
    "\n",
    "fig.update_layout(height=600, width=800, title_text=\"Label Distributions\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc455c-8461-4d35-a8f7-752aa693a44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_examples(dataset, reverse_label_map, n=6):\n",
    "    # get n images from each label in dataset and return as dictionary\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    example_images = {'Benign': [], 'Malignant': [], 'Normal': []}\n",
    "    for x, y in loader:\n",
    "        for i, label in enumerate(y):\n",
    "            label_name = reverse_label_map[int(label)]\n",
    "            if len(example_images[label_name]) < n:\n",
    "                example_images[label_name].append(x[i])\n",
    "        if len(example_images['Malignant']) == n and\\\n",
    "        len(example_images['Benign']) == n and\\\n",
    "        len(example_images['Normal']) == n:\n",
    "            break\n",
    "    return example_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780aecc6-ded0-4bdd-aa29-38ef1207ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some training examples\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "columns = 6\n",
    "rows = 3\n",
    "fig.suptitle('Training Torch Tensor examples', size=16)\n",
    "\n",
    "\n",
    "train_example_images = get_examples(train_viz_dataset.train_subset, reverse_label_map)\n",
    "for i in range(1, columns*rows +1):\n",
    "    idx = i - 1\n",
    "    if idx < 6:            \n",
    "        img = train_example_images['Benign'][idx]\n",
    "    elif idx >= 6 and idx < 12:\n",
    "        img = train_example_images['Malignant'][idx - 6]\n",
    "    else:\n",
    "        img = train_example_images['Normal'][idx - 12]\n",
    "\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if idx == 0 or idx == 6 or idx == 12:\n",
    "        plt.axis('on')\n",
    "        label_name = reverse_label_map[int(idx/6)]\n",
    "        plt.ylabel(label_name, fontsize=16)\n",
    "        plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "        plt.tick_params(axis='y', left=False, labelleft=False)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        plt.imshow(torch.movedim(img, 0, 2), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11500c8-f0c5-4732-86ca-907de1617cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some validation images\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "columns = 6\n",
    "rows = 3\n",
    "fig.suptitle('Validation Torch Tensor examples', size=16)\n",
    "\n",
    "\n",
    "valid_example_images = get_examples(train_viz_dataset.validation_subset, reverse_label_map)\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    idx = i - 1\n",
    "    if idx < 6:            \n",
    "        img = valid_example_images['Benign'][idx]\n",
    "    elif idx >= 6 and idx < 12:\n",
    "        img = valid_example_images['Malignant'][idx - 6]\n",
    "    else:\n",
    "        img = valid_example_images['Normal'][idx - 12]\n",
    "    \n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if idx == 0 or idx == 6 or idx == 12:\n",
    "        plt.axis('on')\n",
    "        label_name = reverse_label_map[int(idx/6)]\n",
    "        plt.ylabel(label_name, fontsize=16)\n",
    "        plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "        plt.tick_params(axis='y', left=False, labelleft=False)\n",
    "\n",
    "    plt.imshow(torch.movedim(img, 0, 2), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f49c77",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "This step calls the model's train function with the dataset that was just prepared. The training function will get the PyTorch feature vector and add on a dense layer based on the number of classes in the dataset. The model is then compiled and trained based on the number of epochs specified in the argument. We also add two more dense layers using the `extra_layers` parameter.\n",
    "\n",
    "To optionally insert additional dense layers between the base model and output layer, `extra_layers=[1024, 512]` will insert two dense layers, the first with 1024 neurons and the second with 512 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a92e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_history = viz_model.train(train_viz_dataset, output_dir=output_dir, epochs=5, seed=10, extra_layers=[1024, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8d57d-a556-43fb-a7e9-3ba7a5328dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_viz_metrics = viz_model.evaluate(train_viz_dataset)\n",
    "test_viz_metrics = viz_model.evaluate(test_viz_dataset)\n",
    "print(validation_viz_metrics)\n",
    "print(test_viz_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6bafe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Save the Computer Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093905b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saved_model_dir = viz_model.export(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4b35b-79d0-4acc-abae-145f81a5e4be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Error Analysis\n",
    "\n",
    "Analyzing the errors via a confusion matrix and ROC and PR curves will help us identify if our model is exibiting any label bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1659f-71f1-4d46-bae4-3dedaac0990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "y_pred = []\n",
    "# get the logit predictions and then convert to probabilities\n",
    "for batch in test_viz_dataset.dataset:\n",
    "    y_pred.append(softmax(viz_model._model(batch[0][None, :]).detach().numpy())[0])\n",
    "\n",
    "y_true =[y for x, y in test_viz_dataset.dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0249827-a1b7-45f2-9c03-3deca2482362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainer import metrics\n",
    "viz_cm = metrics.confusion_matrix(y_true, y_pred, test_viz_dataset.class_names)\n",
    "viz_cm.visualize()\n",
    "print(viz_cm.report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6141e9-5e2a-4ada-9269-47df260b3532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = metrics.plot(y_true, y_pred, test_viz_dataset.class_names)\n",
    "plotter.pr_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d215ac-054b-42c5-be2e-e4aa3233311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff916933-c240-4ef2-b1ca-73c962297958",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8c2de-bb77-4183-a3d5-6e9372bc3bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert one-hot encoded predictions to the index labels\n",
    "y_pred_labels = np.array(y_pred).argmax(axis=1)\n",
    "\n",
    "# get the malignant indexes and then the normal and benign prediction indexes\n",
    "mal_idxs = np.where(np.array(y_true) == label_map_func('Malignant'))[0].tolist()\n",
    "nor_preds = np.where(np.array(y_pred_labels) == label_map_func('Normal'))[0].tolist()\n",
    "ben_preds = np.where(np.array(y_pred_labels) == label_map_func('Benign'))[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69d2d6-a675-45d5-bd3f-02f009853576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get mal examples that were misclassified as ben\n",
    "mal_classified_as_nor = list(set(mal_idxs).intersection(nor_preds))\n",
    "\n",
    "# get mal examples that were misclassified as ben\n",
    "mal_classified_as_ben = list(set(mal_idxs).intersection(ben_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133212d-461e-45a1-82dc-cf2b721a5ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the paths for all mals predicted as nors\n",
    "mal_as_nor_files = [file for file, label in np.array(test_viz_dataset.dataset.samples)[mal_classified_as_nor]]\n",
    "\n",
    "# get the paths for all mals predicted as bens\n",
    "mal_as_ben_files = [file for file, label in np.array(test_viz_dataset.dataset.samples)[mal_classified_as_ben]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba81869-f659-41fb-9a4f-af8f97c6c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "# plot 14 mal_as_nor images\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "columns = 7\n",
    "rows = 2\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    if i == len(mal_as_nor_files):\n",
    "        break\n",
    "    idx = i - 1\n",
    "    image = io.imread(mal_as_nor_files[idx])\n",
    "    \n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.imshow(image)\n",
    "\n",
    "fig.suptitle('Malignant predicted as Normal', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda72f36-59c7-4e2c-afc4-e750b969a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets calculate gradcam on the 0th, 1st and 12th images since they\n",
    "# seem to have tnhe clearest visual of a malignant tumor\n",
    "\n",
    "images = [io.imread(mal_as_nor_files[0]),\n",
    "          io.imread(mal_as_nor_files[1]),\n",
    "          io.imread(mal_as_nor_files[10])]\n",
    "          \n",
    "                    \n",
    "\n",
    "from explainer import cam\n",
    "final_image_dim = (224, 224)\n",
    "targetLayer = viz_model._model.layer4\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Normal'), \n",
    "                      images[0],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Normal'), \n",
    "                      images[1],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Normal'), \n",
    "                      images[2],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e989c2-caf7-4c9b-8496-bf2cc4d72ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 14 mal_as_ben images\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "columns = 7\n",
    "rows = 2\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    idx = i - 1\n",
    "    if idx == len(mal_as_ben_files):\n",
    "        break\n",
    "    image = io.imread(mal_as_ben_files[idx])\n",
    "    \n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.imshow(image)\n",
    "\n",
    "fig.suptitle('Malignant predicted as Benign', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb7a71-3868-421b-9a0a-8e11890a6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets calculate gradcam on the 5th, 10th and 11th images since they\n",
    "# seem to have tnhe clearest visual of a malignant tumor\n",
    "\n",
    "images = [io.imread(mal_as_ben_files[0]),\n",
    "          io.imread(mal_as_ben_files[1]),\n",
    "          io.imread(mal_as_ben_files[2])]\n",
    "          \n",
    "                    \n",
    "\n",
    "final_image_dim = (224, 224)\n",
    "targetLayer = viz_model._model.layer4\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Benign'), \n",
    "                      images[0],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Benign'), \n",
    "                      images[1],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Benign'), \n",
    "                      images[2],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621b571",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2: Text Classification with PyTorch\n",
    "\n",
    "### Get the Model and Dataset\n",
    "Now we will call the model factory to get a pretrained model from HuggingFace and load the annotation file using the dataset factory. We will use clinical-bert for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18cebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up NLP parameters\n",
    "model_name = 'clinical-bert'\n",
    "seq_length = 64\n",
    "batch_size = 5\n",
    "quantization_criterion = 0.05\n",
    "quantization_max_trial = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = model_factory.get_model(model_name=model_name, framework='pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9dff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label map function and reverse label map for the dataset\n",
    "def label_map_func(label):\n",
    "        if label == 'Benign':\n",
    "            return 0\n",
    "        elif label == 'Malignant':\n",
    "            return 1\n",
    "        elif label == 'Normal':\n",
    "            return 2\n",
    "    \n",
    "reverse_label_map = {0: 'Benign', 1: 'Malignant', 2: 'Normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e510e1-4ca5-49e6-9ec7-b59b5047061c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.path.split(os.path.splitext(train_annotation_path)[0] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879bad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_dir, train_file_name =  os.path.split(os.path.splitext(train_annotation_path)[0] +'.csv')\n",
    "train_nlp_dataset = dataset_factory.load_dataset(dataset_dir=train_file_dir,\n",
    "                       use_case='text_classification',\n",
    "                       framework='pytorch',\n",
    "                       dataset_name='brca',\n",
    "                       csv_file_name=train_file_name,\n",
    "                       label_map_func=label_map_func,\n",
    "                       class_names=['Benign', 'Malignant', 'Normal'],\n",
    "                       header=True,\n",
    "                       label_col=label_col,\n",
    "                       shuffle_files=True,\n",
    "                       exclude_cols=[2])\n",
    "\n",
    "test_file_dir, test_file_name =  os.path.split(os.path.splitext(test_annotation_path)[0] +'.csv')\n",
    "test_nlp_dataset = dataset_factory.load_dataset(dataset_dir=test_file_dir,\n",
    "                       use_case='text_classification',\n",
    "                       framework='pytorch',\n",
    "                       dataset_name='brca',\n",
    "                       csv_file_name=test_file_name,\n",
    "                       label_map_func=label_map_func,\n",
    "                       class_names=['Benign', 'Malignant', 'Normal'],\n",
    "                       header=True,\n",
    "                       label_col=label_col,\n",
    "                       shuffle_files=True,\n",
    "                       exclude_cols=[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9ddba",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlp_dataset.preprocess(nlp_model.hub_name, batch_size=batch_size, max_length=seq_length)\n",
    "test_nlp_dataset.preprocess(nlp_model.hub_name, batch_size=batch_size, max_length=seq_length)\n",
    "train_nlp_dataset.shuffle_split(train_pct=0.67, val_pct=0.33, shuffle_files=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2543ce-604f-4666-87be-9c1994cc356c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Corpus analysis\n",
    "Let's take a look at the word distribution across each label to get an idea what BERT will be training on as well make sure that our training and validation datasets are distributed similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36180cff-81a6-4f3d-b4ac-b3314152510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "train_label_count = {'Benign': 0, 'Malignant': 0, 'Normal': 0}\n",
    "for label in train_nlp_dataset.train_subset['label']:\n",
    "    train_label_count[reverse_label_map[int(label)]] += 1\n",
    "\n",
    "print('Training label distribution:')\n",
    "train_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbac9b4-e776-4df8-bb39-1d9625d58ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_label_count = {'Benign': 0, 'Malignant': 0, 'Normal': 0}\n",
    "for label in train_nlp_dataset.validation_subset['label']:\n",
    "    valid_label_count[reverse_label_map[int(label)]] += 1\n",
    "\n",
    "print('Validation label distribution:')\n",
    "valid_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17aec7-74b1-4146-bdf9-339fa31bb15e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_label_count = {'Benign': 0, 'Malignant': 0, 'Normal': 0}\n",
    "for label in test_nlp_dataset.dataset['label']:\n",
    "    test_label_count[reverse_label_map[int(label)]] += 1\n",
    "\n",
    "print('Validation label distribution:')\n",
    "test_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b4c72-268a-4ad5-a3aa-4c47cc9df000",
   "metadata": {},
   "outputs": [],
   "source": [
    "form = {'type':'domain'}\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, specs=[[form, form, form]], subplot_titles=['Training', 'Validation', 'Testing'])\n",
    "fig.add_trace(go.Pie(values=list(train_label_count.values()), labels=list(train_label_count.keys())), 1, 1)\n",
    "fig.add_trace(go.Pie(values=list(valid_label_count.values()), labels=list(valid_label_count.keys())), 1, 2)\n",
    "fig.add_trace(go.Pie(values=list(test_label_count.values()), labels=list(test_label_count.keys())), 1, 3)\n",
    "\n",
    "\n",
    "fig.update_layout(height=600, width=800, title_text=\"Label Distributions\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0e920-ea06-487e-ae70-e5709f7c5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "\n",
    "def get_mc_df(words_list, n=50, ignored_words=[]):\n",
    "    '''\n",
    "    Get's the most common words from a list of words and returns a pd DataFrame for Plotly\n",
    "    '''\n",
    "\n",
    "    frequency_dict = nltk.FreqDist(words_list)\n",
    "    most_common = frequency_dict.most_common(n=500)\n",
    "\n",
    "    \n",
    "    final_fd = pd.DataFrame({'Token': [], 'Frequency': []})\n",
    "    cnt = 0\n",
    "    idx = 0\n",
    "    while(cnt < n):\n",
    "        if most_common[idx][0] in string.punctuation:\n",
    "            print(f'{most_common[idx][0]} is not a word')\n",
    "        else:\n",
    "            final_fd.loc[len(final_fd.index)] = [most_common[idx][0], most_common[idx][1]]\n",
    "            cnt += 1\n",
    "        idx += 1\n",
    "    \n",
    "    return final_fd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b57320-a39c-4c40-9613-31af8575e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_annotation_path)\n",
    "\n",
    "# get string arrays of symptoms for each label\n",
    "mal_text = list(df.loc[df['label'] == 'Malignant']['symptoms'])\n",
    "nor_text = list(df.loc[df['label'] == 'Normal']['symptoms'])\n",
    "ben_text = list(df.loc[df['label'] == 'Benign']['symptoms'])\n",
    "\n",
    "# get tokenized words for each\n",
    "mal_tokenized: list[str] = nltk.word_tokenize(\" \".join(mal_text))\n",
    "nor_tokenized: list[str] = nltk.word_tokenize(\" \".join(nor_text))\n",
    "ben_tokenized: list[str] = nltk.word_tokenize(\" \".join(ben_text))\n",
    "\n",
    "# generate the dataframes necesarry to plot distributions\n",
    "mal_fd = get_mc_df(mal_tokenized)\n",
    "nor_fd = get_mc_df(nor_tokenized)\n",
    "ben_fd = get_mc_df(ben_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212ffc3-00f4-4be7-8424-cd3b54483398",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(mal_fd, x=\"Token\", y='Frequency', color='Frequency', title='Malignant word distribution')\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05363a-1834-4502-aba8-7b88635463cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(nor_fd, x=\"Token\", y='Frequency', color='Frequency', title='Normal word distribution')\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e076e-47a0-4b15-a4b9-9bfe9ddbe052",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(ben_fd, x=\"Token\", y='Frequency', color='Frequency', title='Benign word distribution')\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020303ee",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "This step calls the model's train function with the dataset that was just prepared. The training function will get the pretrained model from HuggingFace and add on a dense layer based on the number of classes in the dataset. The model is then trained using an instance of HuggingFace Trainer for the number of epochs specified. If desired, a native PyTorch loop can be invoked instead of Trainer by setting `use_trainer=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb0612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.set_seed(1)\n",
    "nlp_history = nlp_model.train(train_nlp_dataset, output_dir, epochs=3, use_trainer=True, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70a029",
   "metadata": {},
   "source": [
    "### Save the NLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model.export(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031efd2-6674-416c-abc5-196008efd7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This currently isn't showing the correct output for test\n",
    "train_nlp_metrics = nlp_model.evaluate(train_nlp_dataset)\n",
    "test_nlp_metrics = nlp_model.evaluate(test_nlp_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac80be5-d53f-4add-b10b-b477fa1e2350",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Error analysis\n",
    "\n",
    "We can see that BERT has a much better accuracy than the CNN. Nonetheless, similar to the CNN, let's see where BERT makes mistakes across the three classes using a confusion matrix and ROC and PR curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd77544-21ca-4555-b796-9bb90a5ebf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get predictions in logits (one-hot-encoded)\n",
    "# NOTE: added a new flag to predict function\n",
    "logit_predictions = nlp_model.predict(test_nlp_dataset.dataset, return_raw=True)['logits']\n",
    "#convert logits to probability\n",
    "from scipy.special import softmax\n",
    "y_pred = softmax(logit_predictions.detach().numpy(), axis=1)\n",
    "y_true = test_nlp_dataset.validation_subset['label'].numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2505e-87e7-4cd0-bc24-c3d36556c2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from explainer import metrics\n",
    "\n",
    "nlp_cm = metrics.confusion_matrix(y_true, y_pred, test_nlp_dataset.class_names)\n",
    "nlp_cm.visualize()\n",
    "print(nlp_cm.report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ca2f5-9473-4cc8-acf8-3c14fd1a9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = metrics.plot(y_true, y_pred, test_nlp_dataset.class_names)\n",
    "plotter.pr_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60074e34-2d5a-4d92-b6de-977cc22faa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323fe46-877c-47b6-88ae-5207f91ad636",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6b6ae-a556-453e-91ec-3b806969a7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mal_idxs = np.where(test_nlp_dataset.dataset['label'].numpy() == label_map_func('Malignant'))[0].tolist()\n",
    "ben_preds = np.where(nlp_model.predict(test_nlp_dataset.dataset).numpy() == label_map_func('Benign'))[0].tolist()\n",
    "\n",
    "# get mal examples that were misclassified as ben\n",
    "mal_classified_as_ben = list(set(mal_idxs).intersection(ben_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb972a96-7b3f-4729-8e25-2de239a4bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mal_classified_as_ben_text = test_nlp_dataset.get_text(test_nlp_dataset.dataset[mal_classified_as_ben]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c63607-3801-4ada-8988-7b5a30999e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a prediction function\n",
    "def f(x):\n",
    "    encoded_input = nlp_model._tokenizer(x.tolist(), padding=True, return_tensors='pt')\n",
    "    outputs = nlp_model._model(**encoded_input)\n",
    "    return softmax(outputs.logits.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed89c66-1fbf-4036-88d6-39ee914748f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from explainer import attributions\n",
    "partition_explainer = attributions.partition_text_explainer(f, test_nlp_dataset.class_names, np.array(mal_classified_as_ben_text), r\"\\W+\")\n",
    "partition_explainer.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45752dd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Int8 Quantization\n",
    "\n",
    "We can use the [Intel® Extension for Transformers](https://github.com/intel/intel-extension-for-transformers) to quantize the trained model for faster inference. If you want to run this part of the notebook, make sure you have `intel-extension-for-transformers` installed in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0687ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intel_extension_for_transformers.optimization.trainer import NLPTrainer\n",
    "from intel_extension_for_transformers.optimization import objectives, OptimizedModel, QuantizationConfig\n",
    "from intel_extension_for_transformers.optimization import metrics as nlptk_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9557a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up quantization config\n",
    "tune_metric = nlptk_metrics.Metric(\n",
    "    name=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    is_relative=True,\n",
    "    criterion=quantization_criterion,\n",
    "    weight_ratio=None,\n",
    ")\n",
    "\n",
    "objective = objectives.Objective(\n",
    "    name=\"performance\", greater_is_better=True, weight_ratio=None\n",
    ")\n",
    "\n",
    "quantization_config = QuantizationConfig(\n",
    "    approach=\"PostTrainingDynamic\",\n",
    "    max_trials=quantization_max_trial,\n",
    "    metrics=[tune_metric],\n",
    "    objectives=[objective],\n",
    ")\n",
    "\n",
    "# Set up metrics computation\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = NLPTrainer(model=nlp_model._model,\n",
    "                       train_dataset=train_nlp_dataset.train_subset,\n",
    "                       eval_dataset=train_nlp_dataset.validation_subset,\n",
    "                       compute_metrics=compute_metrics,\n",
    "                       tokenizer=train_nlp_dataset._tokenizer)\n",
    "quantized_model = quantizer.quantize(quant_config=quantization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5f2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = quantizer.evaluate()\n",
    "eval_acc = results.get(\"eval_accuracy\")\n",
    "print(\"Final Eval Accuracy: {:.5f}\".format(eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3611cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save the Quantized NLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer.save_model(os.path.join(output_dir, 'quantized_BERT'))\n",
    "nlp_model._model.config.save_pretrained(os.path.join(output_dir, 'quantized_BERT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1add70-c947-40f2-b401-7f5efa11d994",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Error analysis\n",
    "\n",
    "The quantized BERT model has the same validation accuracy as it's stock counterpart. This does not mean, however, that they perform the same. Let's look at the confusion matrix and PR and ROC curves to see if the errors are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cbea1-f475-4fb4-8ef0-0e25ca2fb5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get predictions in logits (one-hot-encoded)\n",
    "# NOTE: added a new flag to predict function\n",
    "logit_predictions = quantizer.predict(test_nlp_dataset.dataset)[0]\n",
    "#convert logits to probability\n",
    "from scipy.special import softmax\n",
    "y_pred = softmax(logit_predictions, axis=1)\n",
    "y_true = test_nlp_dataset.dataset['label'].numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4506509-2bd1-4605-8850-b9e17ec371cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quant_cm = metrics.confusion_matrix(y_true, y_pred, test_nlp_dataset.class_names)\n",
    "quant_cm.visualize()\n",
    "print(quant_cm.report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92b3d7-6795-49f9-b8ba-7c03ce4f7a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter = metrics.plot(y_true, y_pred, test_nlp_dataset.class_names)\n",
    "plotter.pr_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1ac1b-17a6-4612-b9fe-650c4676368c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24d694f-4da2-431c-ac6b-9f46b2912832",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad1f68-62e6-47cb-bdaa-e858797cd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_score(nlp, vis):\n",
    "    nlp_acc = nlp[0]['model_accuracy']\n",
    "    vis_acc = vis[0]['model_accuracy']\n",
    "    ensb_prognosis = {}\n",
    "    for i in nlp[0]['prognosis'].keys():\n",
    "        ensb_prognosis[i] = (nlp_acc * nlp[0]['prognosis'][i] + vis_acc * vis[0]['prognosis'][i] )\n",
    "    return max(ensb_prognosis, key=ensb_prognosis.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38af4a-99a4-4a21-984b-8d7164e1c450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# the prediction weights are the true-positive scores of each label (optional to use)\n",
    "viz_pred_weights = [viz_cm.df['Benign']['Benign'], viz_cm.df['Malignant']['Malignant'], viz_cm.df['Normal']['Normal']]\n",
    "\n",
    "# final weight of viz is its overall validation accuracy\n",
    "viz_weight = test_viz_metrics[1]\n",
    "\n",
    "# final weight of nlp is its overall validation accuracy\n",
    "nlp_weight = test_nlp_metrics['eval_accuracy']\n",
    "\n",
    "def convert_nomenclature(df_pid):\n",
    "    return 'P' + df_pid[:-1] + '_' + df_pid[-1]\n",
    "\n",
    "def find_files(pid, search_path):\n",
    "    result = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(search_path):\n",
    "        for fname in files:\n",
    "            if pid in fname:\n",
    "                result.append(os.path.join(root,fname))\n",
    "    return result\n",
    "\n",
    "def viz_preds(targets):\n",
    "    preds = []\n",
    "    for i, (path, label) in enumerate(test_viz_dataset._dataset.imgs):\n",
    "        if path in targets:\n",
    "            preds.append(torch.softmax(viz_model._model(test_viz_dataset._dataset[i][0][None, :])[0], dim=-1).cpu().detach().numpy())\n",
    "    return preds\n",
    "\n",
    "def viz_prognosis(targets, weights=[1,1,1]):\n",
    "    preds = viz_preds(targets)\n",
    "    return softmax(sum(preds)/len(preds[0])*weights, axis=0)\n",
    "\n",
    "def nlp_prognosis(text, nlp_model):\n",
    "    encoded_input = nlp_model._tokenizer(np.array(text).tolist(),return_tensors='pt')\n",
    "    return softmax(nlp_model._model(**encoded_input)['logits'].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3b8ea-a916-4034-be8a-c1976bd0d929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pid = []\n",
    "label = []\n",
    "image_paths = []\n",
    "text = []\n",
    "viz_pred = []\n",
    "nlp_pred = []\n",
    "test_df = pd.read_csv(test_annotation_path)\n",
    "\n",
    "# make and save the predictions of the CNN and BERT model\n",
    "for idx, (i, row) in enumerate(test_df.iterrows()):\n",
    "    pid.append(row.Patient_ID)\n",
    "    label.append(row.label)\n",
    "    text.append(row['symptoms'])\n",
    "    image_paths.append(find_files(convert_nomenclature(row.Patient_ID), os.path.join(grouped_image_path)))\n",
    "    viz_pred.append(viz_prognosis(image_paths[idx], viz_pred_weights))\n",
    "    nlp_pred.append(nlp_prognosis(row['symptoms'], nlp_model))\n",
    "\n",
    "ensemble_results = pd.DataFrame({'pid': pid, 'label': label, 'text': text, 'viz_pred': viz_pred, 'nlp_pred': nlp_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3fc60-4aa2-4d52-afcc-28f75100a6da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the ensemble algorithm\n",
    "ensemble_prognosis = viz_weight * ensemble_results['viz_pred'].to_numpy() + nlp_weight * ensemble_results['nlp_pred'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bef7e-e866-49d7-8011-0fd2ee8c6d22",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59bafc-1ab1-4a39-b446-5e95426a1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the results of the ensemble for the confusion matrix\n",
    "y_pred = [np.argmax(i) for i in ensemble_prognosis]\n",
    "n_values = np.max(y_pred) + 1\n",
    "oh_y_pred = np.eye(n_values)[y_pred]\n",
    "y_true = [label_map_func(i) for i in label]\n",
    "\n",
    "ensemble_cm = metrics.confusion_matrix(y_true, oh_y_pred, test_nlp_dataset.class_names)\n",
    "ensemble_cm.visualize()\n",
    "print(ensemble_cm.report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30533617-1c6e-4ee1-8140-9e722010f2b4",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f8c6e-44e4-4b99-8a43-df19fcef42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the first example of the validation set to compare\n",
    "# more closely how the CNN and BERT predict\n",
    "\n",
    "from skimage import io\n",
    "from explainer import cam\n",
    "\n",
    "image_idx = 100\n",
    "\n",
    "print(f'The groundtruth label for {ensemble_results.iloc[1].pid} is {ensemble_results.iloc[image_idx].label}')\n",
    "print(f'The CNN has a softmaxed prediction average across all images of {ensemble_results.iloc[image_idx].viz_pred}')\n",
    "print(f'BERT has a softmax prediction of {ensemble_results.iloc[image_idx].nlp_pred}\\n')\n",
    "\n",
    "\n",
    "\n",
    "images = [io.imread(image_paths[image_idx][0]),\n",
    "          io.imread(image_paths[image_idx][1]),\n",
    "          io.imread(image_paths[image_idx][2]),\n",
    "          io.imread(image_paths[image_idx][3])]\n",
    "io.imshow_collection(images)\n",
    "\n",
    "final_image_dim = (224, 224)\n",
    "targetLayer = viz_model._model.layer4\n",
    "#targetLayer = \"_IPEXConv2d-169\"\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Malignant'), \n",
    "                      images[0],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Malignant'), \n",
    "                      images[1],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Malignant'), \n",
    "                      images[2],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "\n",
    "xgc = cam.x_gradcam(viz_model._model, targetLayer, \n",
    "                      label_map_func('Malignant'), \n",
    "                      images[3],\n",
    "                      final_image_dim,\n",
    "                      'cpu')\n",
    "\n",
    "xgc.visualize()\n",
    "text_for_shap = np.expand_dims(np.array(ensemble_results.iloc[image_idx]['text']), axis=0)\n",
    "ensemble_partition_explainer = attributions.partition_text_explainer(f,  test_nlp_dataset.class_names, text_for_shap, r\"\\W+\")\n",
    "ensemble_partition_explainer.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69df1a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Citations\n",
    "\n",
    "### Data Citation\n",
    "Khaled R., Helal M., Alfarghaly O., Mokhtar O., Elkorany A., El Kassas H., Fahmy A. <b>Categorized Digital Database for Low energy and Subtracted Contrast Enhanced Spectral Mammography images [Dataset].</b> (2021) The Cancer Imaging Archive. DOI:  [10.7937/29kw-ae92](https://doi.org/10.7937/29kw-ae92)\n",
    "\n",
    "### Publication Citation\n",
    "Khaled, R., Helal, M., Alfarghaly, O., Mokhtar, O., Elkorany, A., El Kassas, H., & Fahmy, A. <b>Categorized contrast enhanced mammography dataset for diagnostic and artificial intelligence research.</b> (2022) Scientific Data, Volume 9, Issue 1. DOI: [10.1038/s41597-022-01238-0](https://doi.org/10.1038/s41597-022-01238-0)\n",
    "\n",
    "### TCIA Citation\n",
    "Clark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. <b>The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository</b>, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057. DOI: [10.1007/s10278-013-9622-7](https://doi.org/10.1007/s10278-013-9622-7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
