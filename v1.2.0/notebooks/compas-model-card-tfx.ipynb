{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c450c5ce",
   "metadata": {},
   "source": [
    "# Detecting Issues in Fairness by Generating Model Card from Tensorflow Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fd3c1",
   "metadata": {},
   "source": [
    "In this notebook we will create a TFX pipeline to create a Proxy model for COMPAS (originally published by [Tensorflow Authors](https://github.com/tensorflow/fairness-indicators/blob/r0.38.0/g3doc/tutorials/Fairness_Indicators_Lineage_Case_Study.ipynb)).  First, we will train a `tf.estimator` with defined `eval_input_reciever_fn`. This will allow us to run userdefined metrics with `tensorflow-model-analysis` on seralized `tf.Example`.\n",
    "\n",
    "After this pipeline has be created, we will show how Intel's `ModelCardGen` class can take this `tf.estimator` in the form of an SavedModel and TFRecord to create a Model Card with interactive graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ee99b",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c11b8-2fef-47c0-a97f-5d45a137af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --no-cache-dir --no-deps \\\n",
    "    docker==7.0.0 \\\n",
    "    keras-tuner==1.4.7 \\\n",
    "    kubernetes==29.0.0 \\\n",
    "    ml-metadata==1.14.0 \\\n",
    "    portpicker==1.6.0 \\\n",
    "    tensorflow-transform==1.14.0 \\\n",
    "    tfx==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afebf888",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p compas/data/train compas/data/eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09769e7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Intel Model Card Genorator \n",
    "from intel_ai_safety.model_card_gen.model_card_gen import ModelCardGen\n",
    "from intel_ai_safety.model_card_gen.datasets import TensorflowDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e52507",
   "metadata": {},
   "source": [
    "## Download and preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e81e74",
   "metadata": {},
   "source": [
    "The COMPAS dataset is a common case study in the ML fairness literature<sup>1, 2, 3</sup>, where it is use to apply techniques for identifying and remediating issues around fairness. \n",
    "___\n",
    "\n",
    "1.  Wadsworth, C., Vera, F., Piech, C. (2017). Achieving Fairness Through Adversarial Learning: an Application to Recidivism Prediction. https://arxiv.org/abs/1807.00199.\n",
    "\n",
    "2.  Chouldechova, A., Gâ€™Sell, M., (2017). Fairer and more accurate, but for whom? https://arxiv.org/abs/1707.00046.\n",
    "\n",
    "3.  Berk et al., (2017), Fairness in Criminal Justice Risk Assessments: The State of the Art, https://arxiv.org/abs/1703.09207.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the COMPAS dataset and setup the required filepaths.\n",
    "_DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')\n",
    "_DATA_PATH = 'https://storage.googleapis.com/compas_dataset/cox-violent-parsed.csv'\n",
    "_DATA_FILEPATH = os.path.join('compas', 'data')\n",
    "\n",
    "_COMPAS_DF = pd.read_csv(_DATA_PATH)\n",
    "\n",
    "# To simpliy the case study, we will only use the columns that will be used for\n",
    "# our model.\n",
    "_COLUMN_NAMES = [\n",
    "  'age',\n",
    "  'c_charge_desc',\n",
    "  'c_charge_degree',\n",
    "  'c_days_from_compas',\n",
    "  'is_recid',            # ground truth\n",
    "  'juv_fel_count',\n",
    "  'juv_misd_count',\n",
    "  'juv_other_count',\n",
    "  'priors_count',\n",
    "  'r_days_from_arrest',\n",
    "  'race',\n",
    "  'sex',\n",
    "  'vr_charge_desc',\n",
    "  'score_text',          # COMPAS predction\n",
    "]\n",
    "\n",
    "_GROUND_TRUTH = 'is_recid'\n",
    "_COMPAS_SCORE = 'score_text'\n",
    "\n",
    "_COMPAS_DF = _COMPAS_DF[_COLUMN_NAMES]\n",
    "\n",
    "# We will use 'is_recid' as our ground truth lable, which is boolean value\n",
    "# indicating if a defendant committed another crime. There are some rows with -1\n",
    "# indicating that there is no data. These rows we will drop from training.\n",
    "_COMPAS_DF = _COMPAS_DF[_COMPAS_DF['is_recid'] != -1]\n",
    "_COMPAS_DF = _COMPAS_DF.dropna(subset=['score_text'])\n",
    "_COMPAS_DF['score_text'] = _COMPAS_DF.score_text.map({'Low': 0, 'High': 1, 'Medium': 1})\n",
    "# is_recid field is ground truth to create a COMPAS proxy we will need to train on score_text\n",
    "# _COMPAS_DF = _COMPAS_DF.rename(columns={'is_recid': 'ground_truth', 'score_text': 'compas_score'})\n",
    "\n",
    "# Given the distribution between races in this dataset we will only focuse on\n",
    "# recidivism for African-Americans and Caucasians.\n",
    "_COMPAS_DF = _COMPAS_DF[\n",
    "  _COMPAS_DF['race'].isin(['African-American', 'Caucasian'])]\n",
    "\n",
    "X  = _COMPAS_DF[_COLUMN_NAMES]\n",
    "# to create a COMPAS proxy we will need to train on score_text not to be confused with ground truth is_recid field\n",
    "# y = _COMPAS_DF[[_COMPAS_SCORE]]\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.33, random_state=42)\n",
    "\n",
    "# Load the DataFrame back to a CSV file for our TFX model.\n",
    "X_train.to_csv(os.path.join(_DATA_FILEPATH, 'train', 'train.csv'), index=False, na_rep='')\n",
    "X_test.to_csv(os.path.join(_DATA_FILEPATH, 'eval', 'eval.csv'), index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712ff05",
   "metadata": {},
   "source": [
    "# TFX Pipeline Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffb2d6",
   "metadata": {},
   "source": [
    "We opt to create a custom pipeline script so that we can transform data and train a model saved as artifacts to use in as input in Model Card Generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb20fa",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "_transformer_path = os.path.join('compas', 'transformer.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ce007",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_transformer_path}\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    'sex',\n",
    "    'race',\n",
    "    'c_charge_desc',\n",
    "    'c_charge_degree',\n",
    "]\n",
    "\n",
    "INT_FEATURE_KEYS = [\n",
    "    'age',\n",
    "    'c_days_from_compas',\n",
    "    'juv_fel_count',\n",
    "    'juv_misd_count',\n",
    "    'juv_other_count',\n",
    "    'priors_count',\n",
    "]\n",
    "\n",
    "LABEL_KEY = 'is_recid'\n",
    "\n",
    "# List of the unique values for the items within CATEGORICAL_FEATURE_KEYS.\n",
    "MAX_CATEGORICAL_FEATURE_VALUES = [\n",
    "    2,\n",
    "    6,\n",
    "    513,\n",
    "    14,\n",
    "]\n",
    "\n",
    "\n",
    "def transformed_name(key):\n",
    "  return '{}_xf'.format(key)\n",
    "\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
    "\n",
    "  Args:\n",
    "    inputs: Map from feature keys to raw features.\n",
    "\n",
    "  Returns:\n",
    "    Map from string feature key to transformed feature operations.\n",
    "  \"\"\"\n",
    "  outputs = {}\n",
    "  for key in CATEGORICAL_FEATURE_KEYS:\n",
    "    outputs[transformed_name(key)] = tft.compute_and_apply_vocabulary(\n",
    "        _fill_in_missing(inputs[key]),\n",
    "        vocab_filename=key)\n",
    "\n",
    "  for key in INT_FEATURE_KEYS:\n",
    "    outputs[transformed_name(key)] = tft.scale_to_z_score(\n",
    "        _fill_in_missing(inputs[key]))\n",
    "\n",
    "  # Target label will be to see if the defendant is charged for another crime.\n",
    "  outputs[transformed_name(LABEL_KEY)] = _fill_in_missing(inputs[LABEL_KEY])\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def _fill_in_missing(tensor_value):\n",
    "  \"\"\"Replaces a missing values in a SparseTensor.\n",
    "\n",
    "  Fills in missing values of `tensor_value` with '' or 0, and converts to a\n",
    "  dense tensor.\n",
    "\n",
    "  Args:\n",
    "    tensor_value: A `SparseTensor` of rank 2. Its dense shape should have size\n",
    "      at most 1 in the second dimension.\n",
    "\n",
    "  Returns:\n",
    "    A rank 1 tensor where missing values of `tensor_value` are filled in.\n",
    "  \"\"\"\n",
    "  if not isinstance(tensor_value, tf.sparse.SparseTensor):\n",
    "    return tensor_value\n",
    "  default_value = '' if tensor_value.dtype == tf.string else 0\n",
    "  sparse_tensor = tf.SparseTensor(\n",
    "      tensor_value.indices,\n",
    "      tensor_value.values,\n",
    "      [tensor_value.dense_shape[0], 1])\n",
    "  dense_tensor = tf.sparse.to_dense(sparse_tensor, default_value)\n",
    "  return tf.squeeze(dense_tensor, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5eed0a",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b700a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_trainer_path = os.path.join('compas', 'trainer.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_trainer_path}\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from transformer import *\n",
    "\n",
    "_BATCH_SIZE = 1000\n",
    "_LEARNING_RATE = 0.00001\n",
    "_MAX_CHECKPOINTS = 1\n",
    "_SAVE_CHECKPOINT_STEPS = 999\n",
    "\n",
    "\n",
    "def transformed_names(keys):\n",
    "  return [transformed_name(key) for key in keys]\n",
    "\n",
    "\n",
    "def transformed_name(key):\n",
    "  return '{}_xf'.format(key)\n",
    "\n",
    "\n",
    "def _gzip_reader_fn(filenames):\n",
    "  \"\"\"Returns a record reader that can read gzip'ed files.\n",
    "\n",
    "  Args:\n",
    "    filenames: A tf.string tensor or tf.data.Dataset containing one or more\n",
    "      filenames.\n",
    "\n",
    "  Returns: A nested structure of tf.TypeSpec objects matching the structure of\n",
    "    an element of this dataset and specifying the type of individual components.\n",
    "  \"\"\"\n",
    "  return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
    "\n",
    "\n",
    "# Tf.Transform considers these features as \"raw\".\n",
    "def _get_raw_feature_spec(schema):\n",
    "  \"\"\"Generates a feature spec from a Schema proto.\n",
    "\n",
    "  Args:\n",
    "    schema: A Schema proto.\n",
    "\n",
    "  Returns:\n",
    "    A feature spec defined as a dict whose keys are feature names and values are\n",
    "      instances of FixedLenFeature, VarLenFeature or SparseFeature.\n",
    "  \"\"\"\n",
    "  return schema_utils.schema_as_feature_spec(schema).feature_spec\n",
    "\n",
    "\n",
    "def _example_serving_receiver_fn(tf_transform_output, schema):\n",
    "  \"\"\"Builds the serving in inputs.\n",
    "\n",
    "  Args:\n",
    "    tf_transform_output: A TFTransformOutput.\n",
    "    schema: the schema of the input data.\n",
    "\n",
    "  Returns:\n",
    "    TensorFlow graph which parses examples, applying tf-transform to them.\n",
    "  \"\"\"\n",
    "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
    "  raw_feature_spec.pop(LABEL_KEY)\n",
    "\n",
    "  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "      raw_feature_spec)\n",
    "  serving_input_receiver = raw_input_fn()\n",
    "\n",
    "  transformed_features = tf_transform_output.transform_raw_features(\n",
    "      serving_input_receiver.features)\n",
    "  transformed_features.pop(transformed_name(LABEL_KEY))\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "      transformed_features, serving_input_receiver.receiver_tensors)\n",
    "\n",
    "\n",
    "def _eval_input_receiver_fn(tf_transform_output, schema):\n",
    "  \"\"\"Builds everything needed for the tf-model-analysis to run the model.\n",
    "\n",
    "  Args:\n",
    "    tf_transform_output: A TFTransformOutput.\n",
    "    schema: the schema of the input data.\n",
    "\n",
    "  Returns:\n",
    "    EvalInputReceiver function, which contains:\n",
    "      - TensorFlow graph which parses raw untransformed features, applies the\n",
    "          tf-transform preprocessing operators.\n",
    "      - Set of raw, untransformed features.\n",
    "      - Label against which predictions will be compared.\n",
    "  \"\"\"\n",
    "  # Notice that the inputs are raw features, not transformed features here.\n",
    "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
    "\n",
    "  serialized_tf_example = tf.compat.v1.placeholder(\n",
    "      dtype=tf.string, shape=[None], name='input_example_tensor')\n",
    "\n",
    "  # Add a parse_example operator to the tensorflow graph, which will parse\n",
    "  # raw, untransformed, tf examples.\n",
    "  features = tf.io.parse_example(\n",
    "      serialized=serialized_tf_example, features=raw_feature_spec)\n",
    "\n",
    "  transformed_features = tf_transform_output.transform_raw_features(features)\n",
    "  labels = transformed_features.pop(transformed_name(LABEL_KEY))\n",
    "\n",
    "  receiver_tensors = {'examples': serialized_tf_example}\n",
    "\n",
    "  return tfma.export.EvalInputReceiver(\n",
    "      features=transformed_features,\n",
    "      receiver_tensors=receiver_tensors,\n",
    "      labels=labels)\n",
    "\n",
    "\n",
    "def _input_fn(filenames, tf_transform_output, batch_size=200):\n",
    "  \"\"\"Generates features and labels for training or evaluation.\n",
    "\n",
    "  Args:\n",
    "    filenames: List of CSV files to read data from.\n",
    "    tf_transform_output: A TFTransformOutput.\n",
    "    batch_size: First dimension size of the Tensors returned by input_fn.\n",
    "\n",
    "  Returns:\n",
    "    A (features, indices) tuple where features is a dictionary of\n",
    "      Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  transformed_feature_spec = (\n",
    "      tf_transform_output.transformed_feature_spec().copy())\n",
    "\n",
    "  dataset = tf.compat.v1.data.experimental.make_batched_features_dataset(\n",
    "      filenames,\n",
    "      batch_size,\n",
    "      transformed_feature_spec,\n",
    "      shuffle=False,\n",
    "      reader=_gzip_reader_fn)\n",
    "\n",
    "  transformed_features = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "  # We pop the label because we do not want to use it as a feature while we're\n",
    "  # training.\n",
    "  return transformed_features, transformed_features.pop(\n",
    "      transformed_name(LABEL_KEY))\n",
    "\n",
    "\n",
    "def _keras_model_builder():\n",
    "  \"\"\"Build a keras model for COMPAS dataset classification.\n",
    "  \n",
    "  Returns:\n",
    "    A compiled Keras model.\n",
    "  \"\"\"\n",
    "  feature_columns = []\n",
    "  feature_layer_inputs = {}\n",
    "\n",
    "  for key in transformed_names(INT_FEATURE_KEYS):\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key))\n",
    "    feature_layer_inputs[key] = tf.keras.Input(shape=(1,), name=key)\n",
    "\n",
    "  for key, num_buckets in zip(transformed_names(CATEGORICAL_FEATURE_KEYS),\n",
    "                              MAX_CATEGORICAL_FEATURE_VALUES):\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\n",
    "                key, num_buckets=num_buckets)))\n",
    "    feature_layer_inputs[key] = tf.keras.Input(\n",
    "        shape=(1,), name=key, dtype=tf.dtypes.int32)\n",
    "\n",
    "  feature_columns_input = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "  feature_layer_outputs = feature_columns_input(feature_layer_inputs)\n",
    "\n",
    "  dense_layers = tf.keras.layers.Dense(\n",
    "      20, activation='relu', name='dense_1')(feature_layer_outputs)\n",
    "  dense_layers = tf.keras.layers.Dense(\n",
    "      10, activation='relu', name='dense_2')(dense_layers)\n",
    "  output = tf.keras.layers.Dense(\n",
    "      1, name='predictions')(dense_layers)\n",
    "\n",
    "  model = tf.keras.Model(\n",
    "      inputs=[v for v in feature_layer_inputs.values()], outputs=output)\n",
    "\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "      optimizer=tf.optimizers.Adam(learning_rate=_LEARNING_RATE))\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "# TFX will call this function.\n",
    "def trainer_fn(hparams, schema):\n",
    "  \"\"\"Build the estimator using the high level API.\n",
    "\n",
    "  Args:\n",
    "    hparams: Hyperparameters used to train the model as name/value pairs.\n",
    "    schema: Holds the schema of the training examples.\n",
    "\n",
    "  Returns:\n",
    "    A dict of the following:\n",
    "      - estimator: The estimator that will be used for training and eval.\n",
    "      - train_spec: Spec for training.\n",
    "      - eval_spec: Spec for eval.\n",
    "      - eval_input_receiver_fn: Input function for eval.\n",
    "  \"\"\"\n",
    "  tf_transform_output = tft.TFTransformOutput(hparams.transform_output)\n",
    "\n",
    "  train_input_fn = lambda: _input_fn(\n",
    "      hparams.train_files,\n",
    "      tf_transform_output,\n",
    "      batch_size=_BATCH_SIZE)\n",
    "\n",
    "  eval_input_fn = lambda: _input_fn(\n",
    "      hparams.eval_files,\n",
    "      tf_transform_output,\n",
    "      batch_size=_BATCH_SIZE)\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "      train_input_fn,\n",
    "      max_steps=hparams.train_steps)\n",
    "\n",
    "  serving_receiver_fn = lambda: _example_serving_receiver_fn(\n",
    "      tf_transform_output, schema)\n",
    "\n",
    "  exporter = tf.estimator.FinalExporter('compas', serving_receiver_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "      eval_input_fn,\n",
    "      steps=hparams.eval_steps,\n",
    "      exporters=[exporter],\n",
    "      name='compas-eval')\n",
    "\n",
    "  run_config = tf.estimator.RunConfig(\n",
    "      save_checkpoints_steps=_SAVE_CHECKPOINT_STEPS,\n",
    "      keep_checkpoint_max=_MAX_CHECKPOINTS)\n",
    "\n",
    "  run_config = run_config.replace(model_dir=hparams.serving_model_dir)\n",
    "\n",
    "  estimator = tf.keras.estimator.model_to_estimator(\n",
    "      keras_model=_keras_model_builder(), config=run_config)\n",
    "\n",
    "  # Create an input receiver for TFMA processing.\n",
    "  receiver_fn = lambda: _eval_input_receiver_fn(tf_transform_output, schema)\n",
    "\n",
    "  return {\n",
    "      'estimator': estimator,\n",
    "      'train_spec': train_spec,\n",
    "      'eval_spec': eval_spec,\n",
    "      'eval_input_receiver_fn': receiver_fn\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eeb83b",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pipelie_path = os.path.join('compas', 'pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_pipelie_path}\n",
    "\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "import absl\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx import v1 as tfx\n",
    "from tfx.components import (CsvExampleGen,\n",
    "                            Evaluator,\n",
    "                            Pusher,\n",
    "                            SchemaGen,\n",
    "                            StatisticsGen,\n",
    "                            Trainer,\n",
    "                            Transform)\n",
    "\n",
    "from tfx.components.trainer.executor import Executor\n",
    "from tfx.dsl.components.base import executor_spec\n",
    "\n",
    "from tfx.orchestration import pipeline\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.orchestration.local.local_dag_runner import LocalDagRunner\n",
    "\n",
    "_pipeline_name = 'compas'\n",
    "_compas_root = os.path.join('.', 'compas')\n",
    "_data_path = os.path.join(_compas_root, 'data')\n",
    "# Python module file to inject customized logic into the TFX components. The\n",
    "# Transform and Trainer both require user-defined functions to run successfully.\n",
    "_transformer_file = os.path.join(_compas_root, 'transformer.py')\n",
    "_trainer_file = os.path.join(_compas_root, 'trainer.py')\n",
    "# Path which can be listened to by the model server.  Pusher will output the\n",
    "# trained model here.\n",
    "_serving_model_dir = os.path.join(_compas_root, 'serving_model', _pipeline_name)\n",
    "\n",
    "# Directory and data locations.  This example assumes all of the chicago taxi\n",
    "# example code and metadata library is relative to $HOME, but you can store\n",
    "# these files anywhere on your local filesystem.\n",
    "_tfx_root = os.path.join('compas', 'tfx')\n",
    "_pipeline_root = os.path.join(_tfx_root, 'pipelines', _pipeline_name)\n",
    "# Sqlite ML-metadata db path.\n",
    "_metadata_path = os.path.join(_tfx_root, 'metadata', _pipeline_name,\n",
    "                              'metadata.db')\n",
    "\n",
    "def create_pipeline(\n",
    "    pipeline_name: str,\n",
    "    pipeline_root: str,\n",
    "    data_path: str,\n",
    "    preprocessing_module_file: str,\n",
    "    trainer_module_file: str,\n",
    "    train_args: tfx.proto.TrainArgs,\n",
    "    eval_args: tfx.proto.EvalArgs,\n",
    "    serving_model_dir: str,\n",
    "    metadata_path: str,\n",
    "    schema_path: Optional[str] = None,\n",
    ") -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Implements the compass pipeline with TFX.\"\"\"\n",
    "\n",
    "  # Brings data into the pipeline or otherwise joins/converts training data.\n",
    "    \n",
    "  input = tfx.proto.Input(splits=[\n",
    "                example_gen_pb2.Input.Split(name='train', pattern='train/*'),\n",
    "                example_gen_pb2.Input.Split(name='eval', pattern='eval/*')\n",
    "            ])\n",
    "  example_gen = CsvExampleGen(input_base=data_path, input_config=input)\n",
    "\n",
    "  # Computes statistics over data for visualization and example validation.\n",
    "  statistics_gen = StatisticsGen(\n",
    "      examples=example_gen.outputs['examples'])\n",
    "\n",
    "  if schema_path is None:\n",
    "    # Generates schema based on statistics files.\n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs['statistics'])\n",
    "  else:\n",
    "    # Import user provided schema into the pipeline.\n",
    "    schema_gen = tfx.components.ImportSchemaGen(schema_file=schema_path)\n",
    "    \n",
    "  \n",
    "  # Performs transformations and feature engineering in training and serving.\n",
    "  transform = Transform(\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      schema=schema_gen.outputs['schema'],\n",
    "      module_file=os.path.abspath(preprocessing_module_file))\n",
    "  \n",
    "  # Uses user-provided Python function that implements a model.\n",
    "  trainer_args = {\n",
    "      'module_file': trainer_module_file,\n",
    "      'examples': transform.outputs['transformed_examples'],\n",
    "      'schema': schema_gen.outputs['schema'],\n",
    "      'custom_executor_spec' : executor_spec.ExecutorClassSpec(Executor),\n",
    "      'transform_graph': transform.outputs['transform_graph'],\n",
    "      'train_args': train_args,\n",
    "      'eval_args': eval_args,\n",
    "  }\n",
    "  trainer = Trainer(**trainer_args)\n",
    "  \n",
    "  # Uses TFMA to compute a evaluation statistics over features of a model and\n",
    "  # perform quality validation of a candidate model (compared to a baseline).\n",
    "  eval_config = tfma.EvalConfig(\n",
    "      model_specs=[\n",
    "          tfma.ModelSpec(\n",
    "              label_key='is_recid')\n",
    "      ],\n",
    "      slicing_specs=[\n",
    "          tfma.SlicingSpec(\n",
    "              feature_keys=['race'])\n",
    "      ],\n",
    "      metrics_specs=[\n",
    "          tfma.MetricsSpec(metrics=[\n",
    "              tfma.MetricConfig(\n",
    "                  class_name='BinaryAccuracy'),\n",
    "              tfma.MetricConfig(\n",
    "                  class_name='AUC'),\n",
    "              tfma.MetricConfig(\n",
    "                  class_name='FairnessIndicators',\n",
    "                  config='{\"thresholds\": [0.25, 0.5, 0.75]}')\n",
    "              \n",
    "          ])\n",
    "      ])\n",
    "  evaluator = Evaluator(examples=example_gen.outputs['examples'],\n",
    "                        model=trainer.outputs['model'],\n",
    "                        eval_config=eval_config)\n",
    "\n",
    "  return pipeline.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=[\n",
    "          example_gen,\n",
    "          statistics_gen,\n",
    "          schema_gen,\n",
    "          transform,\n",
    "          trainer,\n",
    "          evaluator,\n",
    "      ],\n",
    "      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
    "          metadata_path)\n",
    "  )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  absl.logging.set_verbosity(absl.logging.INFO)\n",
    "\n",
    "  LocalDagRunner().run(\n",
    "      create_pipeline(\n",
    "          pipeline_name=_pipeline_name,\n",
    "          pipeline_root=_pipeline_root,\n",
    "          data_path=_data_path,\n",
    "          preprocessing_module_file= _transformer_file,\n",
    "          trainer_module_file=_trainer_file,\n",
    "          serving_model_dir=_serving_model_dir,\n",
    "          metadata_path=_metadata_path,\n",
    "          train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
    "          eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {_pipelie_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c881b9",
   "metadata": {},
   "source": [
    "## Model Card Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c14d7",
   "metadata": {},
   "source": [
    "#### Retrieve URIs form MLMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metadata.metadata_store import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "connection_config.sqlite.filename_uri = './compas/tfx/metadata/compas/metadata.db'\n",
    "connection_config.sqlite.connection_mode = 3 # READWRITE_OPENCREATE\n",
    "store = metadata_store.MetadataStore(connection_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = store.get_artifacts_by_type(\"Examples\")[0].uri\n",
    "evaluator = store.get_artifacts_by_type(\"ModelEvaluation\")[-1].uri\n",
    "model = store.get_artifacts_by_type(\"Model\")[-1].uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073a8dc",
   "metadata": {},
   "source": [
    "#### Model and Data Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_path = os.path.join(model, 'Format-Serving')\n",
    "_data_paths = {'eval': TensorflowDataset(dataset_path=os.path.join(data, 'Split-eval', '*.gz')),\n",
    "               'train': TensorflowDataset(dataset_path=os.path.join(data, 'Split-train', '*.gz'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6fc4b",
   "metadata": {},
   "source": [
    "#### Metric Evaluation Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "_project_path = os.path.join('.', 'compas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56334b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "_eval_config = os.path.join(_project_path, 'eval_config.proto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_eval_config}\n",
    "\n",
    "model_specs {\n",
    "    label_key: 'is_recid'\n",
    "  }\n",
    "metrics_specs {\n",
    "    metrics {class_name: \"BinaryAccuracy\"}\n",
    "    metrics {class_name: \"AUC\"}\n",
    "    metrics {class_name: \"ConfusionMatrixPlot\"}\n",
    "    metrics {\n",
    "      class_name: \"FairnessIndicators\"\n",
    "      config: '{\"thresholds\": [0.25, 0.5, 0.75]}'\n",
    "    }\n",
    "  }\n",
    "slicing_specs {}\n",
    "slicing_specs {\n",
    "        feature_keys: 'race'\n",
    "  }\n",
    "options {\n",
    "    include_default_metrics { value: false }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a40d9",
   "metadata": {},
   "source": [
    "#### User defined inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = (\"COMPAS (Correctional Offender Management Profiling for Alternative Sanctions)\"\n",
    "\" is a public dataset, which contains approximately 18,000 criminal cases from \"\n",
    "\"Broward County, Florida between January, 2013 and December, 2014. The data contains\"\n",
    "\" information about 11,000 unique defendants, including criminal history demographics,\"\n",
    "\" and a risk score intended to represent the defendantâ€™s likelihood of reoffending\"\n",
    "\" (recidivism). A machine learning model trained on this data has been used by judges\"\n",
    "\" and parole officers to determine whether or not to set bail and whether or not to\"\n",
    "\" grant parole.\"\n",
    "\n",
    "\"In 2016, an article published in ProPublica found that the COMPAS model was incorrectly\"\n",
    "\" predicting that African-American defendants would recidivate at much higher rates than\"\n",
    "\" their white counterparts while Caucasian would not recidivate at a much higher rate. \"\n",
    "\"For Caucasian defendants, the model made mistakes in the opposite direction, making incorrect predictions \"\n",
    "\"that they wouldnâ€™t commit another crime. The authors went on to show that these biases were likely due to \"\n",
    "\"an uneven distribution in the data between African-Americans and Caucasian defendants. Specifically, the \"\n",
    "\"ground truth label of a negative example (a defendant would not commit another crime) and a positive example \"\n",
    "\"(defendant would commit another crime) were disproportionate between the two races. \"\n",
    "\"Since 2016, the COMPAS dataset has appeared frequently in the ML fairness literature \"\n",
    "\"1, 2, 3, with researchers using it to demonstrate techniques for identifying and remediating \"\n",
    "\"fairness concerns.\"\n",
    "\n",
    "\"It is important to note that developing a machine learning model to predict pre-trial detention \"\n",
    "\"has a number of important ethical considerations. You can learn more about these issues in the \"\n",
    "\"Partnership on AI Report on Algorithmic Risk Assessment Tools in the U.S. Criminal Justice System.\"\n",
    "\" The Partnership on AI is a multi-stakeholder organization -- of which Google is a member -- that \"\n",
    "\"creates guidelines around AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b09fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = {\n",
    "  \"model_details\": {\n",
    "    \"name\": \"COMPAS (Correctional Offender Management Profiling for Alternative Sanctions)\",\n",
    "    \"overview\": overview,\n",
    "    \"owners\": [\n",
    "      {\n",
    "        \"name\": \"Intel XAI Team\",\n",
    "        \"contact\": \"xai@intel.com\"\n",
    "      }\n",
    "    ],\n",
    "    \"references\": [\n",
    "      {\n",
    "        \"reference\": \"Wadsworth, C., Vera, F., Piech, C. (2017). Achieving Fairness Through Adversarial Learning: an Application to Recidivism Prediction. https://arxiv.org/abs/1807.00199.\"\n",
    "      },\n",
    "      {\n",
    "        \"reference\": \"Chouldechova, A., G'Sell, M., (2017). Fairer and more accurate, but for whom? https://arxiv.org/abs/1707.00046.\"\n",
    "      },\n",
    "      {\n",
    "        \"reference\": \"Berk et al., (2017), Fairness in Criminal Justice Risk Assessments: The State of the Art, https://arxiv.org/abs/1703.09207.\"\n",
    "      }\n",
    "    ],\n",
    "    \"graphics\": {\n",
    "      \"description\": \" \"\n",
    "    }\n",
    "  },\n",
    "  \"quantitative_analysis\": {\n",
    "    \"graphics\": {\n",
    "      \"description\": \" \"\n",
    "    }\n",
    "  },\n",
    "  \"schema_version\": \"0.0.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf9e91-3aad-44cc-94f8-f2f6277a062e",
   "metadata": {},
   "source": [
    "## Generating Model Card from TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcg = ModelCardGen.generate(data_sets=_data_paths,\n",
    "                            eval_config=_eval_config,\n",
    "                            model_path=_model_path, \n",
    "                            model_card=mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91213a4e",
   "metadata": {},
   "source": [
    "### Display Model Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef202f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcg.export_html('compas_plotly.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
