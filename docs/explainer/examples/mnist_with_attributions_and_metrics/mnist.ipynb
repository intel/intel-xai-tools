{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac418890-656c-4063-b90c-151957c097b3",
   "metadata": {},
   "source": [
    "# Using Deep and Gradient Explainers to interpret a PyTorch CNN classifier on the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4b774-8c19-4c88-9131-b6d682032f89",
   "metadata": {},
   "source": [
    "### 1. Design the CNN from scatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c16da9-d896-4c88-9984-72b0912d02fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 1\n",
    "device = torch.device('cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(320, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output.log(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('mnist_data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('mnist_data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cc3d8-0082-40e3-b2e3-4b7b2719864b",
   "metadata": {},
   "source": [
    "### 2. Train the CNN on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edec3cb-8ee2-4dad-8ba9-f175f42422e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827d21d-13d5-4cd4-a93a-aa639ec65abe",
   "metadata": {},
   "source": [
    "### 3. Predict the MNIST test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38063b-6b86-4b24-9b83-ca3a0b437a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "y_true = torch.empty(0)\n",
    "y_pred = torch.empty((0, 10))\n",
    "X_test = torch.empty((0, 1, 28, 28))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        X_test = torch.cat((X_test, data))\n",
    "        y_true, y_pred = torch.cat((y_true, target)), torch.cat((y_pred, output))\n",
    "\n",
    "        test_loss += F.nll_loss(output.log(), target).item() # sum up batch loss\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017d195-f344-4568-a684-fa22426922cc",
   "metadata": {},
   "source": [
    "### 4. Survey performance across all classes using the metrics_explainer plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf5aa5-e9b2-4189-820c-651e0670bd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from explainer import metrics\n",
    "\n",
    "classes = np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "\n",
    "# one-hot-encode for metrics explanation\n",
    "oh_y_true = torch.from_numpy(np.eye(int(torch.max(y_true)+1))[list(y_true.numpy().astype(int))])\n",
    "\n",
    "cm = metrics.confusion_matrix(oh_y_true, y_pred, classes)\n",
    "cm.visualize()\n",
    "print(cm.report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd7e1c-43d2-4934-b445-1259ce1a066d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter = metrics.plot(oh_y_true, y_pred, classes)\n",
    "plotter.pr_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55016f-e2d4-4b58-b553-528d4ab10f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca78854-4a03-48b3-bbdc-1f1a02cbcf81",
   "metadata": {},
   "source": [
    "### 5. Explain performance across the classes using the feature_attributions_explainer plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402afd71-eee8-4d2b-a9a8-b31acac28531",
   "metadata": {},
   "source": [
    "##### From (4), it can be observed from the confusion matrix that classes 4 and 9 perform poorly. Additionallly, there is a high misclassification rate exclusively amongst the two labels. In other words, it appears that the CNN if confusing 4's with 9's, and vice-versa. 7.4% of all the 9 examples were misclassified as 4, and 10% of all the 4 examples were misclassified as 9.\n",
    "\n",
    "##### Let's take a closer look at the pixel-based shap values for the test examples where the CNN predicts '9' when the correct groundtruth label is '4'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0425e555-fd7f-49bb-9ee1-40abe2e85b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the prediction indices where the model predicted 9\n",
    "pred_idx = list(np.where(np.argmax(y_pred, axis=1) == 9)[0])\n",
    "# get the groundtruth indices where the true label is 4\n",
    "gt_idx = list(np.where(y_true == 4)[0])\n",
    "\n",
    "# collect the indices where the CNN misclassified 4 as 9\n",
    "matches = list(set(pred_idx).intersection(gt_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe568b27-52a8-47bf-a593-0e3224f16cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from explainer import attributions\n",
    "# run the deep explainer\n",
    "deViz = attributions.deep_explainer(model, X_test[:100], X_test[matches[:6]], classes)\n",
    "deViz.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8a255-0236-462a-8a3b-c749280a06f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instatiate gradient explainer object\n",
    "# run the deep explainer\n",
    "grViz = attributions.gradient_explainer(model, X_test[:100],  X_test[matches[:6]], 2, classes)\n",
    "grViz.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea555792-d870-46bf-8b24-cc686afffcc1",
   "metadata": {},
   "source": [
    "### 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852d37c-f275-4628-b2dd-f9af78d258f4",
   "metadata": {},
   "source": [
    "##### From the deep and gradient explainer visuals, it can be observed that the CNN pays close attention to the top of the digit in distinguishing between a 4 and a 9. On the first and last row of the above gradient explainer visualization we can the 4's are closed. The contributes to postiive shap values (red) for the 9 classification. This begins explaining why the CNN is confusing the two digits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
