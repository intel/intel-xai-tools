

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Explaining Custom CNN MNIST Classification Using the Attributions Explainer &mdash; Intel® Explainable AI Tools 1.3.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=1f29e9d3"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Intel® Explainable AI Tools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html#running-notebooks">Running Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html#support">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../explainer/index.html">Explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_card_gen/index.html">Model Card Generator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Intel/intel-xai-tools">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Explainable AI Tools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Explaining Custom CNN MNIST Classification Using the Attributions Explainer</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/mnist.nblink.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Explaining-Custom-CNN-MNIST-Classification-Using-the-Attributions-Explainer">
<h1>Explaining Custom CNN MNIST Classification Using the Attributions Explainer<a class="headerlink" href="#Explaining-Custom-CNN-MNIST-Classification-Using-the-Attributions-Explainer" title="Link to this heading"></a></h1>
<section id="1.-Design-the-CNN-from-scatch">
<h2>1. Design the CNN from scatch<a class="headerlink" href="#1.-Design-the-CNN-from-scatch" title="Link to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import torch, torchvision
from torchvision import datasets, transforms
from torch import nn, optim
from torch.nn import functional as F
torch.manual_seed(0)

import numpy as np

batch_size = 128
num_epochs = 1
device = torch.device(&#39;cpu&#39;)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()

        self.conv_layers = nn.Sequential(
            nn.Conv2d(1, 10, kernel_size=5),
            nn.MaxPool2d(2),
            nn.ReLU(),
            nn.Conv2d(10, 20, kernel_size=5),
            nn.Dropout(),
            nn.MaxPool2d(2),
            nn.ReLU(),
        )
        self.fc_layers = nn.Sequential(
            nn.Linear(320, 50),
            nn.ReLU(),
            nn.Dropout(),
            nn.Linear(50, 10),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(-1, 320)
        x = self.fc_layers(x)
        return x

def train(model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output.log(), target)
        loss.backward()
        optimizer.step()
        if batch_idx % 100 == 0:
            print(&#39;Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}&#39;.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))


train_loader = torch.utils.data.DataLoader(
    datasets.MNIST(&#39;mnist_data&#39;, train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor()
                   ])),
    batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST(&#39;mnist_data&#39;, train=False, transform=transforms.Compose([
                       transforms.ToTensor()
                   ])),
    batch_size=batch_size, shuffle=True)

model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)
</pre></div>
</div>
</div>
</section>
<section id="2.-Train-the-CNN-on-the-MNIST-dataset">
<h2>2. Train the CNN on the MNIST dataset<a class="headerlink" href="#2.-Train-the-CNN-on-the-MNIST-dataset" title="Link to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for epoch in range(1, num_epochs + 1):
    train(model, device, train_loader, optimizer, epoch)
</pre></div>
</div>
</div>
</section>
<section id="3.-Predict-the-MNIST-test-data">
<h2>3. Predict the MNIST test data<a class="headerlink" href="#3.-Predict-the-MNIST-test-data" title="Link to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># test the model
model.eval()
test_loss = 0
correct = 0
y_true = torch.empty(0)
y_pred = torch.empty((0, 10))
X_test = torch.empty((0, 1, 28, 28))

with torch.no_grad():
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        output = model(data)
        X_test = torch.cat((X_test, data))
        y_true, y_pred = torch.cat((y_true, target)), torch.cat((y_pred, output))

        test_loss += F.nll_loss(output.log(), target).item() # sum up batch loss
        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability
        correct += pred.eq(target.view_as(pred)).sum().item()

test_loss /= len(test_loader.dataset)
print(&#39;\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n&#39;.format(
    test_loss, correct, len(test_loader.dataset),
100. * correct / len(test_loader.dataset)))
</pre></div>
</div>
</div>
</section>
<section id="4.-Survey-performance-across-all-classes-using-the-metrics_explainer-plugin">
<h2>4. Survey performance across all classes using the metrics_explainer plugin<a class="headerlink" href="#4.-Survey-performance-across-all-classes-using-the-metrics_explainer-plugin" title="Link to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from intel_ai_safety.explainer import metrics

classes = np.array([&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;])

cm = metrics.confusion_matrix(y_true, y_pred, classes)
cm.visualize()
print(cm.report)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plotter = metrics.plot(y_true, y_pred, classes)
plotter.pr_curve()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plotter.roc_curve()
</pre></div>
</div>
</div>
</section>
<section id="5.-Explain-performance-across-the-classes-using-the-feature_attributions_explainer-plugin">
<h2>5. Explain performance across the classes using the feature_attributions_explainer plugin<a class="headerlink" href="#5.-Explain-performance-across-the-classes-using-the-feature_attributions_explainer-plugin" title="Link to this heading"></a></h2>
<section id="From-(4),-it-can-be-observed-from-the-confusion-matrix-that-classes-4-and-9-perform-poorly.-Additionallly,-there-is-a-high-misclassification-rate-exclusively-amongst-the-two-labels.-In-other-words,-it-appears-that-the-CNN-if-confusing-4's-with-9's,-and-vice-versa.-7.4%-of-all-the-9-examples-were-misclassified-as-4,-and-10%-of-all-the-4-examples-were-misclassified-as-9.">
<h3>From (4), it can be observed from the confusion matrix that classes 4 and 9 perform poorly. Additionallly, there is a high misclassification rate exclusively amongst the two labels. In other words, it appears that the CNN if confusing 4’s with 9’s, and vice-versa. 7.4% of all the 9 examples were misclassified as 4, and 10% of all the 4 examples were misclassified as 9.<a class="headerlink" href="#From-(4),-it-can-be-observed-from-the-confusion-matrix-that-classes-4-and-9-perform-poorly.-Additionallly,-there-is-a-high-misclassification-rate-exclusively-amongst-the-two-labels.-In-other-words,-it-appears-that-the-CNN-if-confusing-4's-with-9's,-and-vice-versa.-7.4%-of-all-the-9-examples-were-misclassified-as-4,-and-10%-of-all-the-4-examples-were-misclassified-as-9." title="Link to this heading"></a></h3>
</section>
<section id="Let's-take-a-closer-look-at-the-pixel-based-shap-values-for-the-test-examples-where-the-CNN-predicts-'9'-when-the-correct-groundtruth-label-is-'4'.">
<h3>Let’s take a closer look at the pixel-based shap values for the test examples where the CNN predicts ‘9’ when the correct groundtruth label is ‘4’.<a class="headerlink" href="#Let's-take-a-closer-look-at-the-pixel-based-shap-values-for-the-test-examples-where-the-CNN-predicts-'9'-when-the-correct-groundtruth-label-is-'4'." title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># get the prediction indices where the model predicted 9
pred_idx = list(np.where(np.argmax(y_pred, axis=1) == 9)[0])
# get the groundtruth indices where the true label is 4
gt_idx = list(np.where(y_true == 4)[0])

# collect the indices where the CNN misclassified 4 as 9
matches = list(set(pred_idx).intersection(gt_idx))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from intel_ai_safety.explainer.attributions import attributions
# run the deep explainer
deViz = attributions.deep_explainer(model, X_test[:100], X_test[matches[:6]], classes)
deViz.visualize()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># instatiate gradient explainer object
# run the deep explainer
grViz = attributions.gradient_explainer(model, X_test[:100],  X_test[matches[:6]], classes, 2)
grViz.visualize()
</pre></div>
</div>
</div>
</section>
</section>
<section id="6.-Conclusion">
<h2>6. Conclusion<a class="headerlink" href="#6.-Conclusion" title="Link to this heading"></a></h2>
<section id="From-the-deep-and-gradient-explainer-visuals,-it-can-be-observed-that-the-CNN-pays-close-attention-to-the-top-of-the-digit-in-distinguishing-between-a-4-and-a-9.-On-the-first-and-last-row-of-the-above-gradient-explainer-visualization-we-can-the-4's-are-closed.-The-contributes-to-postiive-shap-values-(red)-for-the-9-classification.-This-begins-explaining-why-the-CNN-is-confusing-the-two-digits.">
<h3>From the deep and gradient explainer visuals, it can be observed that the CNN pays close attention to the top of the digit in distinguishing between a 4 and a 9. On the first and last row of the above gradient explainer visualization we can the 4’s are closed. The contributes to postiive shap values (red) for the 9 classification. This begins explaining why the CNN is confusing the two digits.<a class="headerlink" href="#From-the-deep-and-gradient-explainer-visuals,-it-can-be-observed-that-the-CNN-pays-close-attention-to-the-top-of-the-digit-in-distinguishing-between-a-4-and-a-9.-On-the-first-and-last-row-of-the-above-gradient-explainer-visualization-we-can-the-4's-are-closed.-The-contributes-to-postiive-shap-values-(red)-for-the-9-classification.-This-begins-explaining-why-the-CNN-is-confusing-the-two-digits." title="Link to this heading"></a></h3>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>